{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "medinadiego_4_assignment_kaggle_challenge_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/medinadiegoeverardo/DS-Unit-2-Kaggle-Challenge/blob/master/module4/medinadiego_4_assignment_kaggle_challenge_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCc3XZEyG3XV",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Kaggle Challenge, Module 4\n",
        "\n",
        "## Assignment\n",
        "- [ ] If you haven't yet, [review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2), then submit your dataset.\n",
        "- [ ] Plot a confusion matrix for your Tanzania Waterpumps model.\n",
        "- [ ] Continue to participate in our Kaggle challenge. Every student should have made at least one submission that scores at least 60% accuracy (above the majority class baseline).\n",
        "- [ ] Submit your final predictions to our Kaggle competition. Optionally, go to **My Submissions**, and _\"you may select up to 1 submission to be used to count towards your final leaderboard score.\"_\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "- [ ] Read [Maximizing Scarce Maintenance Resources with Data: Applying predictive modeling, precision at k, and clustering to optimize impact](https://towardsdatascience.com/maximizing-scarce-maintenance-resources-with-data-8f3491133050), by Lambda DS3 student Michael Brady. His blog post extends the Tanzania Waterpumps scenario, far beyond what's in the lecture notebook.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Reading\n",
        "- [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/), by Google Research, with  interactive visualizations. _\"A threshold classifier essentially makes a yes/no decision, putting things in one category or another. We look at how these classifiers work, ways they can potentially be unfair, and how you might turn an unfair classifier into a fairer one. As an illustrative example, we focus on loan granting scenarios where a bank may grant or deny a loan based on a single, automatically computed number such as a credit score.\"_\n",
        "- [Notebook about how to calculate expected value from a confusion matrix by treating it as a cost-benefit matrix](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb)\n",
        "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/) by Kevin Markham, with video\n",
        "- [Visualizing Machine Learning Thresholds to Make Better Business Decisions](https://blog.insightdatascience.com/visualizing-machine-learning-thresholds-to-make-better-business-decisions-4ab07f823415)\n",
        "\n",
        "\n",
        "### Doing\n",
        "- [ ] Share visualizations in our Slack channel!\n",
        "- [ ] RandomizedSearchCV / GridSearchCV, for model selection. (See below)\n",
        "- [ ] Stacking Ensemble. (See below)\n",
        "- [ ] More Categorical Encoding. (See below)\n",
        "\n",
        "### RandomizedSearchCV / GridSearchCV, for model selection\n",
        "\n",
        "- _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?\n",
        "\n",
        "### Stacking Ensemble\n",
        "\n",
        "Here's some code you can use to \"stack\" multiple submissions, which is another form of ensembling:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Filenames of your submissions you want to ensemble\n",
        "files = ['submission-01.csv', 'submission-02.csv', 'submission-03.csv']\n",
        "\n",
        "target = 'status_group'\n",
        "submissions = (pd.read_csv(file)[[target]] for file in files)\n",
        "ensemble = pd.concat(submissions, axis='columns')\n",
        "majority_vote = ensemble.mode(axis='columns')[0]\n",
        "\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "submission = sample_submission.copy()\n",
        "submission[target] = majority_vote\n",
        "submission.to_csv('my-ultimate-ensemble-submission.csv', index=False)\n",
        "```\n",
        "\n",
        "\n",
        "### More Categorical Encodings\n",
        "\n",
        "**1.** The article **[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)** mentions 4 encodings:\n",
        "\n",
        "- **\"Categorical Encoding\":** This means using the raw categorical values as-is, not encoded. Scikit-learn doesn't support this, but some tree algorithm implementations do. For example, [Catboost](https://catboost.ai/), or R's [rpart](https://cran.r-project.org/web/packages/rpart/index.html) package.\n",
        "- **Numeric Encoding:** Synonymous with Label Encoding, or \"Ordinal\" Encoding with random order. We can use [category_encoders.OrdinalEncoder](https://contrib.scikit-learn.org/categorical-encoding/ordinal.html).\n",
        "- **One-Hot Encoding:** We can use [category_encoders.OneHotEncoder](http://contrib.scikit-learn.org/categorical-encoding/onehot.html).\n",
        "- **Binary Encoding:** We can use [category_encoders.BinaryEncoder](http://contrib.scikit-learn.org/categorical-encoding/binary.html).\n",
        "\n",
        "\n",
        "**2.** The short video \n",
        "**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)** introduces an interesting idea: use both X _and_ y to encode categoricals.\n",
        "\n",
        "Category Encoders has multiple implementations of this general concept:\n",
        "\n",
        "- [CatBoost Encoder](http://contrib.scikit-learn.org/categorical-encoding/catboost.html)\n",
        "- [James-Stein Encoder](http://contrib.scikit-learn.org/categorical-encoding/jamesstein.html)\n",
        "- [Leave One Out](http://contrib.scikit-learn.org/categorical-encoding/leaveoneout.html)\n",
        "- [M-estimate](http://contrib.scikit-learn.org/categorical-encoding/mestimate.html)\n",
        "- [Target Encoder](http://contrib.scikit-learn.org/categorical-encoding/targetencoder.html)\n",
        "- [Weight of Evidence](http://contrib.scikit-learn.org/categorical-encoding/woe.html)\n",
        "\n",
        "Category Encoder's mean encoding implementations work for regression problems or binary classification problems. \n",
        "\n",
        "For multi-class classification problems, you will need to temporarily reformulate it as binary classification. For example:\n",
        "\n",
        "```python\n",
        "encoder = ce.TargetEncoder(min_samples_leaf=..., smoothing=...) # Both parameters > 1 to avoid overfitting\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train=='functional')\n",
        "X_val_encoded = encoder.transform(X_train, y_val=='functional')\n",
        "```\n",
        "\n",
        "**3.** The **[dirty_cat](https://dirty-cat.github.io/stable/)** library has a Target Encoder implementation that works with multi-class classification.\n",
        "\n",
        "```python\n",
        " dirty_cat.TargetEncoder(clf_type='multiclass-clf')\n",
        "```\n",
        "It also implements an interesting idea called [\"Similarity Encoder\" for dirty categories](https://www.slideshare.net/GaelVaroquaux/machine-learning-on-non-curated-data-154905090).\n",
        "\n",
        "However, it seems like dirty_cat doesn't handle missing values or unknown categories as well as category_encoders does. And you may need to use it with one column at a time, instead of with your whole dataframe.\n",
        "\n",
        "**4. [Embeddings](https://www.kaggle.com/learn/embeddings)** can work well with sparse / high cardinality categoricals.\n",
        "\n",
        "_**I hope it’s not too frustrating or confusing that there’s not one “canonical” way to encode categorcals. It’s an active area of research and experimentation! Maybe you can make your own contributions!**_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGlu1G5XnPNY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkckzx86CecD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw9TjjHxCiQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB31-r0Ab27e",
        "colab_type": "text"
      },
      "source": [
        "### feature eng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV56nW2eMTWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# suspected duplicates\n",
        "\n",
        "train_dupl = train[['source', 'source_type', 'waterpoint_type', 'waterpoint_type_group','extraction_type', 'extraction_type_group',\n",
        "                 'extraction_type_class', 'payment', 'payment_type', 'quantity', 'quantity_group']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xr5iK5LN6zD",
        "colab_type": "code",
        "outputId": "4d57c074-d97c-4a5d-9420-f2a93e38d234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "train_dupl.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_type</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>waterpoint_type_group</th>\n",
              "      <th>extraction_type</th>\n",
              "      <th>extraction_type_group</th>\n",
              "      <th>extraction_type_class</th>\n",
              "      <th>payment</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>quantity</th>\n",
              "      <th>quantity_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59395</th>\n",
              "      <td>spring</td>\n",
              "      <td>spring</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>pay per bucket</td>\n",
              "      <td>per bucket</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59396</th>\n",
              "      <td>river</td>\n",
              "      <td>river/lake</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>pay annually</td>\n",
              "      <td>annually</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59397</th>\n",
              "      <td>machine dbh</td>\n",
              "      <td>borehole</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>swn 80</td>\n",
              "      <td>swn 80</td>\n",
              "      <td>handpump</td>\n",
              "      <td>pay monthly</td>\n",
              "      <td>monthly</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59398</th>\n",
              "      <td>shallow well</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>nira/tanira</td>\n",
              "      <td>nira/tanira</td>\n",
              "      <td>handpump</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>insufficient</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59399</th>\n",
              "      <td>shallow well</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>nira/tanira</td>\n",
              "      <td>nira/tanira</td>\n",
              "      <td>handpump</td>\n",
              "      <td>pay when scheme fails</td>\n",
              "      <td>on failure</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             source   source_type  ...      quantity quantity_group\n",
              "59395        spring        spring  ...        enough         enough\n",
              "59396         river    river/lake  ...        enough         enough\n",
              "59397   machine dbh      borehole  ...        enough         enough\n",
              "59398  shallow well  shallow well  ...  insufficient   insufficient\n",
              "59399  shallow well  shallow well  ...        enough         enough\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsWYkYbUPhPG",
        "colab_type": "code",
        "outputId": "72ef2e13-1567-4969-acc5-8facc57859e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "train.source.value_counts()\n",
        "# dropping source_type since source has more unique values\n",
        "# also waterpoint_type_group since waterpoint_type has 1 unique value more"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spring                  17021\n",
              "shallow well            16824\n",
              "machine dbh             11075\n",
              "river                    9612\n",
              "rainwater harvesting     2295\n",
              "hand dtw                  874\n",
              "lake                      765\n",
              "dam                       656\n",
              "other                     212\n",
              "unknown                    66\n",
              "Name: source, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtBELoaCWltg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replacing_dates(df):\n",
        "  df['date_recorded'] = pd.to_datetime(df['date_recorded'], infer_datetime_format=True)\n",
        "  df['year_recorded'] = df['date_recorded'].dt.year\n",
        "  df['month_recorded'] = df['date_recorded'].dt.month\n",
        "  df['day_recorded'] = df['date_recorded'].dt.day\n",
        "\n",
        "replacing_dates(train)\n",
        "replacing_dates(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU9sAmMtcfFr",
        "colab_type": "code",
        "outputId": "30456593-0ec1-4529-bfb7-0851f1d5270f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>date_recorded</th>\n",
              "      <th>funder</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>installer</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>wpt_name</th>\n",
              "      <th>num_private</th>\n",
              "      <th>basin</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>region</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>lga</th>\n",
              "      <th>ward</th>\n",
              "      <th>population</th>\n",
              "      <th>public_meeting</th>\n",
              "      <th>recorded_by</th>\n",
              "      <th>scheme_management</th>\n",
              "      <th>scheme_name</th>\n",
              "      <th>permit</th>\n",
              "      <th>construction_year</th>\n",
              "      <th>extraction_type</th>\n",
              "      <th>extraction_type_group</th>\n",
              "      <th>extraction_type_class</th>\n",
              "      <th>management</th>\n",
              "      <th>management_group</th>\n",
              "      <th>payment</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>water_quality</th>\n",
              "      <th>quality_group</th>\n",
              "      <th>quantity</th>\n",
              "      <th>quantity_group</th>\n",
              "      <th>source</th>\n",
              "      <th>source_type</th>\n",
              "      <th>source_class</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>waterpoint_type_group</th>\n",
              "      <th>status_group</th>\n",
              "      <th>year_recorded</th>\n",
              "      <th>month_recorded</th>\n",
              "      <th>day_recorded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69572</td>\n",
              "      <td>6000.0</td>\n",
              "      <td>2011-03-14</td>\n",
              "      <td>Roman</td>\n",
              "      <td>1390</td>\n",
              "      <td>Roman</td>\n",
              "      <td>34.938093</td>\n",
              "      <td>-9.856322</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Nyasa</td>\n",
              "      <td>Mnyusi B</td>\n",
              "      <td>Iringa</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>Ludewa</td>\n",
              "      <td>Mundindi</td>\n",
              "      <td>109</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>VWC</td>\n",
              "      <td>Roman</td>\n",
              "      <td>False</td>\n",
              "      <td>1999</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay annually</td>\n",
              "      <td>annually</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8776</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-03-06</td>\n",
              "      <td>Grumeti</td>\n",
              "      <td>1399</td>\n",
              "      <td>GRUMETI</td>\n",
              "      <td>34.698766</td>\n",
              "      <td>-2.147466</td>\n",
              "      <td>Zahanati</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Nyamara</td>\n",
              "      <td>Mara</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>Serengeti</td>\n",
              "      <td>Natta</td>\n",
              "      <td>280</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>Other</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>2010</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>wug</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34310</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2013-02-25</td>\n",
              "      <td>Lottery Club</td>\n",
              "      <td>686</td>\n",
              "      <td>World vision</td>\n",
              "      <td>37.460664</td>\n",
              "      <td>-3.821329</td>\n",
              "      <td>Kwa Mahundi</td>\n",
              "      <td>0</td>\n",
              "      <td>Pangani</td>\n",
              "      <td>Majengo</td>\n",
              "      <td>Manyara</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>Simanjiro</td>\n",
              "      <td>Ngorika</td>\n",
              "      <td>250</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>VWC</td>\n",
              "      <td>Nyumba ya mungu pipe scheme</td>\n",
              "      <td>True</td>\n",
              "      <td>2009</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay per bucket</td>\n",
              "      <td>per bucket</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>dam</td>\n",
              "      <td>dam</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2013-01-28</td>\n",
              "      <td>Unicef</td>\n",
              "      <td>263</td>\n",
              "      <td>UNICEF</td>\n",
              "      <td>38.486161</td>\n",
              "      <td>-11.155298</td>\n",
              "      <td>Zahanati Ya Nanyumbu</td>\n",
              "      <td>0</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Mahakamani</td>\n",
              "      <td>Mtwara</td>\n",
              "      <td>90</td>\n",
              "      <td>63</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>Nanyumbu</td>\n",
              "      <td>58</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>VWC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>1986</td>\n",
              "      <td>submersible</td>\n",
              "      <td>submersible</td>\n",
              "      <td>submersible</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>dry</td>\n",
              "      <td>dry</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>borehole</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>non functional</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19728</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2011-07-13</td>\n",
              "      <td>Action In A</td>\n",
              "      <td>0</td>\n",
              "      <td>Artisan</td>\n",
              "      <td>31.130847</td>\n",
              "      <td>-1.825359</td>\n",
              "      <td>Shuleni</td>\n",
              "      <td>0</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Kyanyamisa</td>\n",
              "      <td>Kagera</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>Karagwe</td>\n",
              "      <td>Nyakasimbi</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>GeoData Consultants Ltd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>never pay</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "      <td>2011</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  amount_tsh date_recorded  ... year_recorded  month_recorded day_recorded\n",
              "0  69572      6000.0    2011-03-14  ...          2011               3           14\n",
              "1   8776         0.0    2013-03-06  ...          2013               3            6\n",
              "2  34310        25.0    2013-02-25  ...          2013               2           25\n",
              "3  67743         0.0    2013-01-28  ...          2013               1           28\n",
              "4  19728         0.0    2011-07-13  ...          2011               7           13\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWbtovmDSLkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_drop = ['payment', 'extraction_type', 'waterpoint_type_group', 'quantity_group', 'source_type', 'date_recorded']\n",
        "target = 'status_group'\n",
        "\n",
        "features = train.columns.drop(columns_drop + [target])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyhDzvolhfRl",
        "colab_type": "code",
        "outputId": "861c20ec-bc68-404b-e0d3-27ee2bb0d11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'amount_tsh', 'funder', 'gps_height', 'installer', 'longitude',\n",
              "       'latitude', 'wpt_name', 'num_private', 'basin', 'subvillage', 'region',\n",
              "       'region_code', 'district_code', 'lga', 'ward', 'population',\n",
              "       'public_meeting', 'recorded_by', 'scheme_management', 'scheme_name',\n",
              "       'permit', 'construction_year', 'extraction_type_group',\n",
              "       'extraction_type_class', 'management', 'management_group',\n",
              "       'payment_type', 'water_quality', 'quality_group', 'quantity', 'source',\n",
              "       'source_class', 'waterpoint_type', 'year_recorded', 'month_recorded',\n",
              "       'day_recorded'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHBvLzsKXnRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace 'none' with np.nan, impute later. no need to reduce cardinality (ordinal encoder will be used)\n",
        "import numpy as np\n",
        "train['wpt_name'] = train['wpt_name'].replace('none', np.nan)\n",
        "# replacing_nulls_with_nulls(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhxppTOZYtjG",
        "colab_type": "code",
        "outputId": "72ae90d6-9b5c-4804-9cb3-7d6acb23b067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "def replacing_nulls_with_nulls(df):\n",
        "  cols = df.columns\n",
        "  cols = list(cols) # train.columns.to_list()\n",
        "  those_null = []\n",
        "  for col in cols:\n",
        "    if df[col].isnull().any() == False:\n",
        "      continue\n",
        "    \n",
        "    df[col] = df[col].replace(0, np.nan)\n",
        "    those_null.append(col)\n",
        "  return those_null\n",
        "\n",
        "replacing_nulls_with_nulls(train)\n",
        "replacing_nulls_with_nulls(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['funder',\n",
              " 'installer',\n",
              " 'subvillage',\n",
              " 'public_meeting',\n",
              " 'scheme_management',\n",
              " 'scheme_name',\n",
              " 'permit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-vpIl5aDp3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WzHLaS1TUY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train[features]\n",
        "y_train = train[target]\n",
        "x_test = test[features]\n",
        "\n",
        "target = 'status_group'\n",
        "\n",
        "features = train.columns.drop(columns_drop + [target])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do2Gu8sChtzA",
        "colab_type": "text"
      },
      "source": [
        "### pipeline, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD_IQtMriGgQ",
        "colab_type": "code",
        "outputId": "3187d996-b83d-4cc6-ed18-1a4ee62403db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import category_encoders as ce\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(), \n",
        "    RandomForestClassifier(random_state=10))\n",
        "\n",
        "param_distributions = {\n",
        "    'simpleimputer__strategy': ['mean', 'median'], \n",
        "    'randomforestclassifier__n_estimators': randint(50, 300), # range(1, len(X_train.columns)+1)\n",
        "    'randomforestclassifier__max_depth': [5, 10, 15, 20], \n",
        "    'randomforestclassifier__max_features': uniform(0, 1), \n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    pipeline, \n",
        "    param_distributions=param_distributions, \n",
        "    n_iter=5, \n",
        "    cv=3, \n",
        "    verbose=10,\n",
        "    return_train_score=True, \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "search.fit(x_train, y_train);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  9.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lgIK81ioCW",
        "colab_type": "code",
        "outputId": "96d3dab8-f978-4c0a-9306-1789e8d4603d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('best hyperparameters', search.best_params_)\n",
        "print('best accuracy score: ', search.best_score_) \n",
        "y_pred = search.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best hyperparameters {'randomforestclassifier__max_depth': 15, 'randomforestclassifier__max_features': 0.18884867296076535, 'randomforestclassifier__n_estimators': 173, 'simpleimputer__strategy': 'mean'}\n",
            "best accuracy score:  0.7987710437710438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yw4R5ITn8Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission = sample_submission.copy()\n",
        "# submission['status_group'] = y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JRmVni3o09w",
        "colab_type": "code",
        "outputId": "718194b4-4897-4354-cf6a-1591910fc967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "submission.to_csv('medinadiegokaggle_4.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0a1552024e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'medinadiegokaggle_4.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR5iOviVo2G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('medinadiegokaggle_4.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjG85aR_KubY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX_oYPemKwBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGsGE9dyJpag",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it-44CH8KHt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(train, random_state=10, train_size=.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCoQmbTYMBAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_drop = ['payment', 'extraction_type', 'waterpoint_type_group', 'quantity_group', 'source_type', 'date_recorded']\n",
        "target = 'status_group'\n",
        "\n",
        "features = train.columns.drop(columns_drop + [target])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIX3-JXGLxvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replacing_dates(train)\n",
        "replacing_dates(validation)\n",
        "\n",
        "# replace 'none' with np.nan, impute later. no need to reduce cardinality (ordinal encoder will be used)\n",
        "train['wpt_name'] = train['wpt_name'].replace('none', np.nan)\n",
        "replacing_nulls_with_nulls(train)\n",
        "replacing_nulls_with_nulls(validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v811dAhMPbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx_train = train[features]\n",
        "yy_train = train[target]\n",
        "xx_val = validation[features]\n",
        "yy_val = validation[target]\n",
        "xx_test = test[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkthcqwUKWk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPiihRBvJoxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'), \n",
        "    RandomForestClassifier(random_state=10, max_depth=20, \n",
        "                           max_features=0.0287, n_estimators=238))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhbr2P5XLW68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(xx_train, yy_train)\n",
        "y_pred = pipeline.predict(xx_val)\n",
        "print('Validation Accuracy', pipeline.score(yy_val, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7uAco2Co8S0",
        "colab_type": "text"
      },
      "source": [
        "### confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A13WmAgIll2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "confusion_matrix(yy_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWjBKSQUEYL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "to_normalize = confusion_matrix(yy_val, y_pred)\n",
        "norm = Normalizer().transform(to_normalize)\n",
        "\n",
        "labels = unique_labels(y_pred)\n",
        "columns = [f'predicted {label}' for label in labels]\n",
        "index = [f'actual {label}' for label in labels]\n",
        "table_2 = pd.DataFrame(norm, columns=columns, index=index)\n",
        "table_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPP5XjecFqHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# same results as normalizer\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "to_minmax = confusion_matrix(yy_val, y_pred)\n",
        "minmax = MinMaxScaler().fit_transform(to_minmax)\n",
        "\n",
        "labels_2 = unique_labels(y_pred)\n",
        "columns_2 = [f'predicted {label}' for label in labels_2]\n",
        "index_2 = [f'actual {label}' for label in labels_2]\n",
        "table_3 = pd.DataFrame(norm, columns=columns_2, index=index_2)\n",
        "table_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0bzA5t8HJfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_2 = unique_labels(y_pred)\n",
        "columns_2 = [f'predicted {label}' for label in labels_2]\n",
        "index_2 = [f'actual {label}' for label in labels_2]\n",
        "table_3 = pd.DataFrame(norm, columns=columns_2, index=index_2)\n",
        "sns.heatmap(table_3, cmap='BuPu_r', fmt='.2%', annot=True) # .1f, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaPjugfqE6lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def con_array(y_true, y_pred):\n",
        "  labels = unique_labels(y_pred)\n",
        "  columns = [f'predicted {label}' for label in labels]\n",
        "  index = [f'actual {label}' for label in labels]\n",
        "  return columns, index\n",
        "\n",
        "con_array(yy_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SktFh9Qul7EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_array_list(y_true, y_pred):\n",
        "  labels = unique_labels(y_pred)\n",
        "  columns = [f'predicted {label}' for label in labels]\n",
        "  index = [f'actual {label}' for label in labels]\n",
        "  table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
        "                       columns=columns, index=index)\n",
        "  return table\n",
        "\n",
        "convert_array_list(yy_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR_55_GiAGJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_array_list(y_true, y_pred):\n",
        "  labels = unique_labels(y_pred)\n",
        "  columns = [f'predicted {label}' for label in labels]\n",
        "  index = [f'actual {label}' for label in labels]\n",
        "  table = pd.DataFrame(confusion_matrix(y_true, y_pred), \n",
        "                       columns=columns, index=index)\n",
        "  return sns.heatmap(table, annot=True, cmap='CMRmap_r', fmt='d') # fmt='d' changes numerical notation\n",
        "\n",
        "convert_array_list(yy_val, y_pred);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDwMPObLDETq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_pred = 5957+201+3386\n",
        "total_pred = 61+466+537+112+1126+34+5957+201+3386\n",
        "correct_pred / total_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7MDmO07KJky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('best accuracy score: ', search.best_score_)\n",
        "print(accuracy_score(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSyVrb27KXxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(y_pred == y_train) / len(y_pred) # what"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL0_bocYLBXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEX5I3l4LWcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_array_list(y_train, y_pred);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY5Czl7EMajd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_non_func_pred = 21761+72+79\n",
        "correct_non_funct = 21761"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDwB1nzyMgcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# precision\n",
        "\n",
        "correct_non_funct / total_non_func_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XWNK06TM447",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recall\n",
        "actual_non_func = 1060+3+21761\n",
        "correct_non_funct / actual_non_func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEyM3TP5N48L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ogGBY6N5fn",
        "colab_type": "text"
      },
      "source": [
        "### precision, recall, thresholds, and predicted probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBpW0sSGN-fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOiQd5WvN_yP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnKOmq6nOBL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTFmK_4OH0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# based on historical data, if you randomly chose waterpumps to inspect, then \n",
        "# about 46% of the waterpumps would need repairs, and 54% would not need repairs\n",
        "\n",
        "trips = 2000\n",
        "print(f'Baseline: {trips * 0.46} waterpumps repairs in {trips} trips')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQU6XuNYOVaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# REDEFINING our target. Identify which waterpumps are non-functional or are functional but needs repair\n",
        "\n",
        "y_train = y_train != 'functional' # give me those that != functional\n",
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zauxb8v9Or6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceNVekN7Oyke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(x_test) == len(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lppWRO4MPCdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline.fit(x_train, y_train)\n",
        "y_pred = search.predict(x_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWe9FGMOQTto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convert_array_list(y_train, y_pred); "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Ayp5w6QoEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}